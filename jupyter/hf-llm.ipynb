{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Load dataset\n",
    "stock_ds = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced bidirectional dataset...\n",
      "Original dataset size: 551\n",
      "Enhanced bidirectional dataset size: 9918\n"
     ]
    }
   ],
   "source": [
    "# Create bidirectional training data with more variations\n",
    "def create_enhanced_bidirectional_data(original_dataset):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for example in original_dataset['train']:\n",
    "        ticker = example['text']\n",
    "        company = example['label']\n",
    "        \n",
    "        # Add multiple variations for better learning\n",
    "        variations_per_pair = 3  # Repeat each mapping multiple times\n",
    "        \n",
    "        for _ in range(variations_per_pair):\n",
    "            # Add ticker -> ticker mapping (identity)\n",
    "            texts.append(ticker)\n",
    "            labels.append(ticker)\n",
    "            \n",
    "            texts.append(ticker.lower())\n",
    "            labels.append(ticker)\n",
    "            \n",
    "            # Add company -> ticker mapping\n",
    "            texts.append(company)\n",
    "            labels.append(ticker)\n",
    "            \n",
    "            # Add lowercase variations\n",
    "            texts.append(company.lower())\n",
    "            labels.append(ticker)\n",
    "            \n",
    "            # Add uppercase variations\n",
    "            texts.append(company.upper())\n",
    "            labels.append(ticker)\n",
    "            \n",
    "            # Add title case\n",
    "            texts.append(company.title())\n",
    "            labels.append(ticker)\n",
    "    \n",
    "    return Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "\n",
    "# Create enhanced bidirectional dataset\n",
    "print(\"Creating enhanced bidirectional dataset...\")\n",
    "bidirectional_ds = create_enhanced_bidirectional_data(dataset)\n",
    "\n",
    "print(f\"Original dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Enhanced bidirectional dataset size: {len(bidirectional_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n",
      "\u001b[32m     29\u001b[39m embeddings = model.encode(aliases, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Push to Pinecone\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-east-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     34\u001b[39m index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# assuming it's a dense index\u001b[39;00m\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Upsert vectors\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtaujenis/personal_projects/LlamaRAG/.conda/lib/python3.12/site-packages/pinecone/deprecation_warnings.py:39\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m     12\u001b[39m     example = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \u001b[33m    import os\u001b[39m\n",
      "\u001b[32m     14\u001b[39m \u001b[33m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        )\u001b[39m\n",
      "\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     32\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \n",
      "\u001b[32m     34\u001b[39m \u001b[33mPlease create an instance of the Pinecone class instead.\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     38\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: init is no longer a top-level attribute of the pinecone package.\n",
      "\n",
      "Please create an instance of the Pinecone class instead.\n",
      "\n",
      "Example:\n",
      "\n",
      "    import os\n",
      "    from pinecone import Pinecone, ServerlessSpec\n",
      "\n",
      "    pc = Pinecone(\n",
      "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
      "    )\n",
      "\n",
      "    # Now do stuff\n",
      "    if 'my_index' not in pc.list_indexes().names():\n",
      "        pc.create_index(\n",
      "            name='my_index', \n",
      "            dimension=1536, \n",
      "            metric='euclidean',\n",
      "            spec=ServerlessSpec(\n",
      "                cloud='aws',\n",
      "                region='us-west-2'\n",
      "            )\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from pinecone import (\n",
    "    Pinecone,\n",
    "    ServerlessSpec,\n",
    "    CloudProvider,\n",
    "    AwsRegion,\n",
    "    VectorType\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "\n",
    "# Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\", environment=\"us-east-1\")\n",
    "index = pinecone.Index(\"stock-index\")  # assuming it's a dense index\n",
    "\n",
    "# Upsert vectors\n",
    "to_upsert = [\n",
    "    (aliases[i], embeddings[i], {\"ticker\": tickers[i]})\n",
    "    for i in range(len(aliases))\n",
    "]\n",
    "index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n",
      "\u001b[32m     29\u001b[39m embeddings = model.encode(aliases, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Push to Pinecone\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-east-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     34\u001b[39m index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# assuming it's a dense index\u001b[39;00m\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Upsert vectors\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtaujenis/personal_projects/LlamaRAG/.conda/lib/python3.12/site-packages/pinecone/deprecation_warnings.py:39\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m     12\u001b[39m     example = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \u001b[33m    import os\u001b[39m\n",
      "\u001b[32m     14\u001b[39m \u001b[33m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        )\u001b[39m\n",
      "\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     32\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \n",
      "\u001b[32m     34\u001b[39m \u001b[33mPlease create an instance of the Pinecone class instead.\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     38\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: init is no longer a top-level attribute of the pinecone package.\n",
      "\n",
      "Please create an instance of the Pinecone class instead.\n",
      "\n",
      "Example:\n",
      "\n",
      "    import os\n",
      "    from pinecone import Pinecone, ServerlessSpec\n",
      "\n",
      "    pc = Pinecone(\n",
      "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
      "    )\n",
      "\n",
      "    # Now do stuff\n",
      "    if 'my_index' not in pc.list_indexes().names():\n",
      "        pc.create_index(\n",
      "            name='my_index', \n",
      "            dimension=1536, \n",
      "            metric='euclidean',\n",
      "            spec=ServerlessSpec(\n",
      "                cloud='aws',\n",
      "                region='us-west-2'\n",
      "            )\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import pinecone\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "\n",
    "# Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\", environment=\"us-east-1\")\n",
    "index = pinecone.Index(\"stock-index\")  # assuming it's a dense index\n",
    "\n",
    "# Upsert vectors\n",
    "to_upsert = [\n",
    "    (aliases[i], embeddings[i], {\"ticker\": tickers[i]})\n",
    "    for i in range(len(aliases))\n",
    "]\n",
    "index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tickers: 551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 9918/9918 [00:00<00:00, 475130.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Create label mappings\n",
    "unique_tickers = list(set(bidirectional_ds['label']))\n",
    "label2id = {ticker: i for i, ticker in enumerate(unique_tickers)}\n",
    "id2label = {i: ticker for i, ticker in enumerate(unique_tickers)}\n",
    "\n",
    "print(f\"Number of unique tickers: {len(unique_tickers)}\")\n",
    "\n",
    "# Filter and shuffle the dataset\n",
    "ds = bidirectional_ds.filter(lambda x: x['text'] is not None and str(x['text']).strip() != \"\")\n",
    "ds = ds.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9918/9918 [00:00<00:00, 53808.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)  # Reduced max_length\n",
    "    tokenized[\"labels\"] = [label2id[label] for label in examples[\"label\"]]\n",
    "    return tokenized\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)\n",
    "tokenized_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Use a larger model for better capacity\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Using full BERT instead of DistilBERT\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ticker_with_confidence(input_text):\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    return id2label[predicted_class], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardtaujenis/rtaujenis/personal_projects/LlamaRAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import (\n",
    "    Pinecone,\n",
    "    ServerlessSpec,\n",
    "    CloudProvider,\n",
    "    AwsRegion,\n",
    "    VectorType\n",
    ")\n",
    "\n",
    "class EmbeddingStockMapper:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", pinecone_api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\"):\n",
    "        # Initialize the embedding model\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Initialize Pinecone (old API)\n",
    "        pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index = pc.Index(\"stock-index\")\n",
    "        \n",
    "    def get_stock_ticker(self, query):\n",
    "        # Get embedding for the query\n",
    "        query_embedding = self.model.encode(query, convert_to_numpy=True)\n",
    "        \n",
    "        # Search in Pinecone\n",
    "        results = self.index.query(\n",
    "            vector=query_embedding.tolist(),\n",
    "            top_k=1,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        if results.matches:\n",
    "            return results.matches[0].metadata['ticker']\n",
    "        return None\n",
    "\n",
    "# Initialize the mapper\n",
    "mapper = EmbeddingStockMapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: AAPL -> Ticker: AAPL\n",
      "Query: Apple Inc. -> Ticker: AAPL\n",
      "Query: apple -> Ticker: AAPL\n",
      "Query: What is the current stock price of Tesla -> Ticker: TSLA\n",
      "Query: Google -> Ticker: GOOGL\n",
      "Query: google -> Ticker: GOOGL\n",
      "Query: TSLA -> Ticker: TSLA\n",
      "Query: Tesla -> Ticker: TSLA\n",
      "Query: tesla -> Ticker: TSLA\n",
      "Query: Microsoft Corporation -> Ticker: MSFT\n",
      "Query: microsoft -> Ticker: MSFT\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\"AAPL\", \"Apple Inc.\", \"apple\", \"What is the current stock price of Tesla.\", \"Google\", \"google\", \"TSLA\", \"Tesla\", \"tesla\", \"Microsoft Corporation\", \"microsoft\"]\n",
    "\n",
    "for query in test_queries:\n",
    "    ticker = mapper.get_stock_ticker(query)\n",
    "    print(f\"Query: {query} -> Ticker: {ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n",
      "\u001b[32m     29\u001b[39m embeddings = model.encode(aliases, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Push to Pinecone\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-east-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     34\u001b[39m index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# assuming it's a dense index\u001b[39;00m\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Upsert vectors\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtaujenis/personal_projects/LlamaRAG/.conda/lib/python3.12/site-packages/pinecone/deprecation_warnings.py:39\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m     12\u001b[39m     example = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \u001b[33m    import os\u001b[39m\n",
      "\u001b[32m     14\u001b[39m \u001b[33m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        )\u001b[39m\n",
      "\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     32\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \n",
      "\u001b[32m     34\u001b[39m \u001b[33mPlease create an instance of the Pinecone class instead.\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     38\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: init is no longer a top-level attribute of the pinecone package.\n",
      "\n",
      "Please create an instance of the Pinecone class instead.\n",
      "\n",
      "Example:\n",
      "\n",
      "    import os\n",
      "    from pinecone import Pinecone, ServerlessSpec\n",
      "\n",
      "    pc = Pinecone(\n",
      "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
      "    )\n",
      "\n",
      "    # Now do stuff\n",
      "    if 'my_index' not in pc.list_indexes().names():\n",
      "        pc.create_index(\n",
      "            name='my_index', \n",
      "            dimension=1536, \n",
      "            metric='euclidean',\n",
      "            spec=ServerlessSpec(\n",
      "                cloud='aws',\n",
      "                region='us-west-2'\n",
      "            )\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import pinecone\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "\n",
    "# Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\", environment=\"us-east-1\")\n",
    "index = pinecone.Index(\"stock-index\")  # assuming it's a dense index\n",
    "\n",
    "# Upsert vectors\n",
    "to_upsert = [\n",
    "    (aliases[i], embeddings[i], {\"ticker\": tickers[i]})\n",
    "    for i in range(len(aliases))\n",
    "]\n",
    "index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n",
      "\u001b[32m     29\u001b[39m embeddings = model.encode(aliases, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Push to Pinecone\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-east-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     34\u001b[39m index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# assuming it's a dense index\u001b[39;00m\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Upsert vectors\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtaujenis/personal_projects/LlamaRAG/.conda/lib/python3.12/site-packages/pinecone/deprecation_warnings.py:39\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m     12\u001b[39m     example = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \u001b[33m    import os\u001b[39m\n",
      "\u001b[32m     14\u001b[39m \u001b[33m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        )\u001b[39m\n",
      "\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     32\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \n",
      "\u001b[32m     34\u001b[39m \u001b[33mPlease create an instance of the Pinecone class instead.\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     38\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: init is no longer a top-level attribute of the pinecone package.\n",
      "\n",
      "Please create an instance of the Pinecone class instead.\n",
      "\n",
      "Example:\n",
      "\n",
      "    import os\n",
      "    from pinecone import Pinecone, ServerlessSpec\n",
      "\n",
      "    pc = Pinecone(\n",
      "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
      "    )\n",
      "\n",
      "    # Now do stuff\n",
      "    if 'my_index' not in pc.list_indexes().names():\n",
      "        pc.create_index(\n",
      "            name='my_index', \n",
      "            dimension=1536, \n",
      "            metric='euclidean',\n",
      "            spec=ServerlessSpec(\n",
      "                cloud='aws',\n",
      "                region='us-west-2'\n",
      "            )\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import pinecone\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "\n",
    "# Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\", environment=\"us-east-1\")\n",
    "index = pinecone.Index(\"stock-index\")  # assuming it's a dense index\n",
    "\n",
    "# Upsert vectors\n",
    "to_upsert = [\n",
    "    (aliases[i], embeddings[i], {\"ticker\": tickers[i]})\n",
    "    for i in range(len(aliases))\n",
    "]\n",
    "index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n",
      "\u001b[32m     29\u001b[39m embeddings = model.encode(aliases, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Step 5: Push to Pinecone\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-east-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     34\u001b[39m index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# assuming it's a dense index\u001b[39;00m\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Upsert vectors\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rtaujenis/personal_projects/LlamaRAG/.conda/lib/python3.12/site-packages/pinecone/deprecation_warnings.py:39\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m     12\u001b[39m     example = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     13\u001b[39m \u001b[33m    import os\u001b[39m\n",
      "\u001b[32m     14\u001b[39m \u001b[33m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        )\u001b[39m\n",
      "\u001b[32m     31\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     32\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \n",
      "\u001b[32m     34\u001b[39m \u001b[33mPlease create an instance of the Pinecone class instead.\u001b[39m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     38\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: init is no longer a top-level attribute of the pinecone package.\n",
      "\n",
      "Please create an instance of the Pinecone class instead.\n",
      "\n",
      "Example:\n",
      "\n",
      "    import os\n",
      "    from pinecone import Pinecone, ServerlessSpec\n",
      "\n",
      "    pc = Pinecone(\n",
      "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
      "    )\n",
      "\n",
      "    # Now do stuff\n",
      "    if 'my_index' not in pc.list_indexes().names():\n",
      "        pc.create_index(\n",
      "            name='my_index', \n",
      "            dimension=1536, \n",
      "            metric='euclidean',\n",
      "            spec=ServerlessSpec(\n",
      "                cloud='aws',\n",
      "                region='us-west-2'\n",
      "            )\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import pinecone\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "\n",
    "# Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_2WAoZn_SnZJQepsKcJEK1qkpzJUCwgHUCuRhgmu3oJ7tih5xpEMDPnK2CrugA2hKw44XGU\", environment=\"us-east-1\")\n",
    "index = pinecone.Index(\"stock-index\")  # assuming it's a dense index\n",
    "\n",
    "# Upsert vectors\n",
    "to_upsert = [\n",
    "    (aliases[i], embeddings[i], {\"ticker\": tickers[i]})\n",
    "    for i in range(len(aliases))\n",
    "]\n",
    "index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pinecone' has no attribute 'Pinecone'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the mapper\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mapper = \u001b[43mEmbeddingStockMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[32m      5\u001b[39m test_queries = [\u001b[33m\"\u001b[39m\u001b[33mAAPL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mApple\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mapple\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mGOOGL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mGoogle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mEmbeddingStockMapper.__init__\u001b[39m\u001b[34m(self, model_name, pinecone_api_key, pinecone_env)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.model = SentenceTransformer(model_name)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Initialize Pinecone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPinecone\u001b[49m.init(api_key=pinecone_api_key, environment=pinecone_env)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.index = pinecone.Index(\u001b[33m\"\u001b[39m\u001b[33mstock-index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pinecone' has no attribute 'Pinecone'"
     ]
    }
   ],
   "source": [
    "test_queries = [\"AAPL\", \"Apple\", \"apple\", \"GOOGL\", \"Google\", \"google\"]\n",
    "\n",
    "for query in test_queries:\n",
    "    ticker = mapper.get_stock_ticker(query)\n",
    "    print(f\"Query: {query} -> Ticker: {ticker}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
