{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 2/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 3/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 4/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 5/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 6/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 7/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 8/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 9/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 10/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 11/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 12/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 13/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 14/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 15/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 16/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 17/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 18/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 19/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 20/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 21/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 22/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 23/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 24/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 25/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 26/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 27/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 28/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 29/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 30/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 31/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 32/33 has been embedded and uploaded (50 vectors)\n",
      "Batch 33/33 has been embedded and uploaded (30 vectors)\n",
      "All batches completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "pc_api_key= os.getenv(\"PINECONE_API_KEY\")\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Step 2: Create alias map\n",
    "alias_to_ticker = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "    # Optional: add lowercase ticker too\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Step 3: Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)\n",
    "\n",
    "# Step 5: Push to Pinecone\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "index = pc.Index(\"stock-index\")\n",
    "\n",
    "# Prepare vectors in correct format\n",
    "vectors = []\n",
    "for i in range(len(aliases)):\n",
    "    vectors.append({\n",
    "        \"id\": f\"stock_{i}\",\n",
    "        \"values\": embeddings[i].tolist(),\n",
    "        \"metadata\": {\"ticker\": tickers[i], \"alias\": aliases[i]}\n",
    "    })\n",
    "\n",
    "# Batch upsert to avoid 2MB limit\n",
    "batch_size = 50\n",
    "total_batches = (len(vectors) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    batch = vectors[i:i + batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "    batch_num = i // batch_size + 1\n",
    "    print(f\"Batch {batch_num}/{total_batches} has been embedded and uploaded ({len(batch)} vectors)\")\n",
    "\n",
    "print(\"All batches completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Mozes721/stock-crypto-weather-dataset\", data_files=\"stock_mapper_training.csv\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Create alias map\n",
    "alias_to_ticker = {}\n",
    "for _, row in df.iterrows():\n",
    "    ticker = row['text'].upper()\n",
    "    name = row['label'].lower()\n",
    "    alias_to_ticker[ticker] = ticker\n",
    "    alias_to_ticker[name] = ticker\n",
    "    alias_to_ticker[ticker.lower()] = ticker\n",
    "\n",
    "# Prepare for embedding\n",
    "aliases = list(alias_to_ticker.keys())\n",
    "tickers = [alias_to_ticker[a] for a in aliases]\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(aliases, convert_to_numpy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
